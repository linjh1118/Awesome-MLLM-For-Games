Webgpt: Browser-assisted question-answering with human feedback
Reinforcement learning on web interfaces using workflow-guided exploration
World of bits: An open-domain platform for web-based agents
Webshop: Towards scalable real-world web interaction with grounded language agents
React: Synergizing reasoning and acting in language models
Make llm a testing expert: Bringing human-like interaction to mobile gui testing via functionality-aware decisions
Visualwebbench: How far have multimodal llms evolved in web page understanding and grounding?
Autoglm: Autonomous foundation agents for guis
Fill in the blank: Context-aware automated text input generation for mobile gui testing
Omniparser for pure vision based gui agent
Weblinx: Real-world website navigation with multi-turn dialogue
Caution for the environment: Multimodal agents are susceptible to environmental distractions
Gaia: a benchmark for general ai assistants
Dynasaur: Large language agents beyond predefined actions
Mobileflow: A multimodal llm for mobile gui agent
Autotask: Executing arbitrary voice commands by exploring and learning from mobile gui
Webcanvas: Benchmarking web agents in online environments
Agent q: Advanced reasoning and learning for autonomous ai agents
Webrl: Training llm web agents via self-evolving online curriculum reinforcement learning
Naviqate: Functionality-guided web application navigation
Falconui: Understanding gui before following user instructions
Taskbench: Benchmarking large language models for task automation
Assistgui: Task-oriented pc graphical user interface automation
Navigating the digital world as humans do: Universal visual grounding for gui agents
Is your llm secretly a world model of the internet? model-based planning for web agents
A real-world webagent with planning, long context understanding, and program synthesis
Webvoyager: Building an end-to-end web agent with large multimodal models
Cogagent: A visual language model for gui agents
Understanding the planning of llm agents: A survey
Openwebagent: An open toolkit to enable web agents on large language models
Videowebarena: Evaluating long context multimodal agents with video understanding web tasks
A challenge benchmark for web agents
Grounding open-domain instructions to automate web support tasks
Agentoccam: A simple yet strong baseline for llm-based web agents
Thought propagation: An analogical approach to complex reasoning with large language models
Large language model-brained gui agents: A survey
Appagent: Multimodal agents as smartphone users
Mobileexperts: A dynamic tool-enabled agent team in mobile devices
Privacyasst: Safeguarding user privacy in tool-using large language model agents
Webpilot: A versatile and autonomous multi-agent system for web task execution with strategic exploration
Mmina: Benchmarking multihop multimodal internet agents
An indepth survey of large language model-based artificial intelligence agents
Language agent tree search unifies reasoning acting and planning in language models
Webarena: A realistic web environment for building autonomous agents
Webarena: A realistic web environment for building autonomous agents
Moba: A two-level agent system for efficient mobile task automation
Toolchain*: Efficient action space navigation in large language models with a* search
Vga: Vision gui assistant-minimizing hallucinations through image-centric fine-tuning
AppAgentX: Evolving GUI Agents as Proficient Smartphone Users
Towards Trustworthy GUI Agents: A Survey