PCA-Bench: Evaluating Multimodal Large Language Models in Perception-Cognition-Action Chain
DSGBench: A Diverse Strategic Game Benchmark for Evaluating LLM-based Agents in Complex Decision-Making Environments
TMGBench: A Systematic Game Benchmark for Evaluating Strategic Reasoning Abilities of LLMs
Atari-GPT: Benchmarking Multimodal Large Language Models as Low-Level Policies in Atari Games
Hokoff: Real Game Dataset from Honor of Kings and its Offline Reinforcement Learning Benchmarks
A Benchmark Environment for Offline Reinforcement Learning in Racing Games
Large Language Models Play StarCraft II: Benchmarks and A Chain of Summarization Approach
The ThreeDWorld Transport Challenge: A Visually Guided Task-and-Motion Planning Benchmark for Physically Realistic Embodied AI
Evaluating Large Language Models with Grid-Based Game Competitions: An Extensible LLM Benchmark and Leaderboard
MuG: A Multimodal Classification Benchmark on Game Data with Tabular, Textual, and Visual Fields
GlitchBench: Can large multimodal models detect video game glitches?
Using Game Play to Investigate Multimodal and Conversational Grounding in Large Multimodal Models
AvalonBench: Evaluating LLMs Playing the Game of Avalon
Steve-Eye: Equipping LLM-based Embodied Agents with Visual Perception in Open Worlds
Creative Agents: Empowering Agents with Imagination for Creative Tasks
MineLand: Simulating Large-Scale Multi-Agent Interactions with Limited Multimodal Senses and Physical Needs
MindAgent: Emergent Gaming Interaction
BEHAVIOR: Benchmark for Everyday Household Activities in Virtual, Interactive, and Ecological Environments
Deciphering Digital Detectives: Understanding LLM Behaviors and Capabilities in Multi-Agent Mystery Games
LLM-Coordination: Evaluating and Analyzing Multi-agent Coordination Abilities in Large Language Models
SimulBench: Evaluating Language Models with Creative Simulation Tasks
Visual Encoders for Data-Efficient Imitation Learning in Modern Video Games
Predicting Outcomes in Video Games with Long Short Term Memory Networks
SOTOPIA-Ï€: Interactive Learning of Socially Intelligent Language Agents
EmoLLM: Multimodal Emotional Understanding Meets Large Language Models
AgentSims: An Open-Source Sandbox for Large Language Model Evaluation
Benchmarking End-to-End Behavioural Cloning on Video Games
Benchmarking Cognitive Abilities of the Brain with Computer Games
Triangulating LLM Progress through Benchmarks, Games, and Cognitive Tests
Solving Urban Network Security Games: Learning Platform, Benchmark, and Challenge for AI Research
How Different AI Chatbots Behave? Benchmarking Large Language Models in Behavioral Economics Games
AuctionNet: A Novel Benchmark for Decision-Making in Large-Scale Games
From Code to Play: Benchmarking Program Search for Games Using Large Language Models
OpenHoldem: A Benchmark for Large-Scale Imperfect-Information Game Research
Large Language Models are Pretty Good Zero-Shot Video Game Bug Detectors